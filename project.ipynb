{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7413c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions (full): 11495242\n",
      "Interactions after sampling: 223313\n",
      "Users after sampling: 50000\n",
      "Items after sampling: 27490\n",
      "Train shape: (173313, 20)\n",
      "Test shape: (31306, 20)\n",
      "Matrix shape: (31306, 22773)\n",
      "Final matrix shape: (31306, 22773)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82a8c9f6b2b4e42a17aedb0367eedaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n",
      "\n",
      "===== ALS MODEL =====\n",
      "Recall@10: 0.05803999233373794\n",
      "Precision@10: 0.0058039992333736015\n",
      "\n",
      "===== POPULARITY BASELINE =====\n",
      "Recall@10: 0.1490129687599821\n",
      "Precision@10: 0.014901296875999412\n",
      "\n",
      "===== HYBRID MODEL =====\n",
      "Recall@10: 0.060755126812751546\n",
      "Precision@10: 0.006075512681274947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"train.parquet\")\n",
    "\n",
    "print(\"Total interactions (full):\", len(df))\n",
    "\n",
    "\n",
    "\n",
    "sample_users = (\n",
    "    df[\"user_id\"]\n",
    "    .drop_duplicates()\n",
    "    .sample(50000, random_state=42)\n",
    ")\n",
    "\n",
    "df = df[df[\"user_id\"].isin(sample_users)]\n",
    "\n",
    "print(\"Interactions after sampling:\", len(df))\n",
    "print(\"Users after sampling:\", df[\"user_id\"].nunique())\n",
    "print(\"Items after sampling:\", df[\"product_id\"].nunique())\n",
    "\n",
    "\n",
    "df[\"interaction_weight\"] = df[\"event_type\"].map({\n",
    "    \"cart\": 1,\n",
    "    \"purchase\": 5\n",
    "})\n",
    "\n",
    "df[\"interaction_weight\"] = np.log1p(df[\"interaction_weight\"])\n",
    "\n",
    "\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for user_id, group in df.groupby(\"user_id\"):\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "\n",
    "    group = group.sort_values(\"timestamp\")\n",
    "    train_list.append(group.iloc[:-1])\n",
    "    test_list.append(group.iloc[-1:])\n",
    "\n",
    "train_df = pd.concat(train_list)\n",
    "test_df = pd.concat(test_list)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "user_ids = train_df[\"user_id\"].unique()\n",
    "product_ids = train_df[\"product_id\"].unique()\n",
    "\n",
    "user_to_index = {u: i for i, u in enumerate(user_ids)}\n",
    "product_to_index = {p: i for i, p in enumerate(product_ids)}\n",
    "index_to_product = {i: p for p, i in product_to_index.items()}\n",
    "\n",
    "train_df[\"user_index\"] = train_df[\"user_id\"].map(user_to_index)\n",
    "train_df[\"product_index\"] = train_df[\"product_id\"].map(product_to_index)\n",
    "\n",
    "\n",
    "\n",
    "user_item_matrix = csr_matrix(\n",
    "    (\n",
    "        train_df[\"interaction_weight\"],\n",
    "        (train_df[\"user_index\"], train_df[\"product_index\"])\n",
    "    ),\n",
    "    shape=(len(user_to_index), len(product_to_index))\n",
    ").astype(\"float32\")\n",
    "\n",
    "print(\"Matrix shape:\", user_item_matrix.shape)\n",
    "\n",
    "\n",
    "\n",
    "nonzero_items = user_item_matrix.getnnz(axis=0) > 0\n",
    "user_item_matrix = user_item_matrix[:, nonzero_items]\n",
    "\n",
    "product_ids = product_ids[nonzero_items]\n",
    "product_to_index = {p: i for i, p in enumerate(product_ids)}\n",
    "index_to_product = {i: p for p, i in product_to_index.items()}\n",
    "\n",
    "print(\"Final matrix shape:\", user_item_matrix.shape)\n",
    "\n",
    "\n",
    "\n",
    "alpha = 40\n",
    "confidence_matrix = user_item_matrix * alpha\n",
    "\n",
    "\n",
    "\n",
    "als_model = AlternatingLeastSquares(\n",
    "    factors=32,\n",
    "    regularization=0.1,\n",
    "    iterations=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "als_model.fit(confidence_matrix)\n",
    "\n",
    "print(\"Model trained successfully.\")\n",
    "\n",
    "\n",
    "item_popularity = np.array(user_item_matrix.sum(axis=0)).ravel()\n",
    "popular_items = np.argsort(-item_popularity)\n",
    "\n",
    "def recommend_popular(k=10):\n",
    "    return [index_to_product[i] for i in popular_items[:k]]\n",
    "\n",
    "\n",
    "\n",
    "def recommend_als(user_id, k=10):\n",
    "\n",
    "    if user_id not in user_to_index:\n",
    "        return recommend_popular(k)\n",
    "\n",
    "    user_index = user_to_index[user_id]\n",
    "    user_row = user_item_matrix[user_index:user_index + 1]\n",
    "\n",
    "    item_indices, scores = als_model.recommend(\n",
    "        userid=user_index,\n",
    "        user_items=user_row,\n",
    "        N=k,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "\n",
    "    return [index_to_product[i] for i in item_indices]\n",
    "\n",
    "\n",
    "\n",
    "def recommend_hybrid(user_id, k=10):\n",
    "\n",
    "    popular_recs = [index_to_product[i] for i in popular_items[:50]]\n",
    "\n",
    "    if user_id not in user_to_index:\n",
    "        return popular_recs[:k]\n",
    "\n",
    "    user_index = user_to_index[user_id]\n",
    "    user_row = user_item_matrix[user_index:user_index + 1]\n",
    "\n",
    "    item_indices, scores = als_model.recommend(\n",
    "        userid=user_index,\n",
    "        user_items=user_row,\n",
    "        N=50,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "\n",
    "    if len(item_indices) == 0:\n",
    "        return popular_recs[:k]\n",
    "\n",
    "    # Normalize ALS scores\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "\n",
    "    # Popularity scores\n",
    "    pop_scores = item_popularity[item_indices]\n",
    "    pop_scores = (pop_scores - pop_scores.min()) / (pop_scores.max() - pop_scores.min() + 1e-8)\n",
    "\n",
    "    # Weighted blend\n",
    "    final_scores = 0.6 * scores + 0.4 * pop_scores\n",
    "\n",
    "    top_idx = np.argsort(-final_scores)[:k]\n",
    "\n",
    "    return [index_to_product[item_indices[i]] for i in top_idx]\n",
    "\n",
    "\n",
    "\n",
    "def recall_at_k(model=\"hybrid\", k=10):\n",
    "\n",
    "    hits = 0\n",
    "    total = 0\n",
    "\n",
    "    for user_id, group in test_df.groupby(\"user_id\"):\n",
    "\n",
    "        actual_items = set(group[\"product_id\"])\n",
    "\n",
    "        if model == \"als\":\n",
    "            recommended = set(recommend_als(user_id, k))\n",
    "        elif model == \"popular\":\n",
    "            recommended = set(recommend_popular(k))\n",
    "        else:\n",
    "            recommended = set(recommend_hybrid(user_id, k))\n",
    "\n",
    "        hits += len(actual_items & recommended)\n",
    "        total += len(actual_items)\n",
    "\n",
    "    return hits / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def precision_at_k(model=\"hybrid\", k=10):\n",
    "\n",
    "    total_precision = 0\n",
    "    user_count = 0\n",
    "\n",
    "    for user_id, group in test_df.groupby(\"user_id\"):\n",
    "\n",
    "        actual_items = set(group[\"product_id\"])\n",
    "\n",
    "        if model == \"als\":\n",
    "            recommended = set(recommend_als(user_id, k))\n",
    "        elif model == \"popular\":\n",
    "            recommended = set(recommend_popular(k))\n",
    "        else:\n",
    "            recommended = set(recommend_hybrid(user_id, k))\n",
    "\n",
    "        total_precision += len(actual_items & recommended) / k\n",
    "        user_count += 1\n",
    "\n",
    "    return total_precision / user_count if user_count > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n===== ALS MODEL =====\")\n",
    "print(\"Recall@10:\", recall_at_k(\"als\", 10))\n",
    "print(\"Precision@10:\", precision_at_k(\"als\", 10))\n",
    "\n",
    "print(\"\\n===== POPULARITY BASELINE =====\")\n",
    "print(\"Recall@10:\", recall_at_k(\"popular\", 10))\n",
    "print(\"Precision@10:\", precision_at_k(\"popular\", 10))\n",
    "\n",
    "print(\"\\n===== HYBRID MODEL =====\")\n",
    "print(\"Recall@10:\", recall_at_k(\"hybrid\", 10))\n",
    "print(\"Precision@10:\", precision_at_k(\"hybrid\", 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b14ca462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(als_model, open(\"als_model.pkl\", \"wb\"))\n",
    "pickle.dump(user_item_matrix, open(\"user_item_matrix.pkl\", \"wb\"))\n",
    "pickle.dump(user_to_index, open(\"user_to_index.pkl\", \"wb\"))\n",
    "pickle.dump(index_to_product, open(\"index_to_product.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89c5009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['110760953',\n",
       " '251333420',\n",
       " '310119844',\n",
       " '339009312',\n",
       " '402839293',\n",
       " '406827257',\n",
       " '407602302',\n",
       " '415514618',\n",
       " '415987845',\n",
       " '417810135']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(user_to_index.keys())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b8eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['event_time', 'event_type', 'product_id', 'brand', 'price', 'user_id',\n",
      "       'user_session', 'target', 'cat_0', 'cat_1', 'cat_2', 'cat_3',\n",
      "       'timestamp', 'ts_hour', 'ts_minute', 'ts_weekday', 'ts_day', 'ts_month',\n",
      "       'ts_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"train.parquet\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d85c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " 'als_model.pkl',\n",
       " 'app.py',\n",
       " 'index_to_item.pkl',\n",
       " 'index_to_product.pkl',\n",
       " 'popular_products.pkl',\n",
       " 'product_names.pkl',\n",
       " 'project.ipynb',\n",
       " 'README.md',\n",
       " 'recommender.py',\n",
       " 'requirements.txt',\n",
       " 'train_model.py',\n",
       " 'user_item_matrix.pkl',\n",
       " 'user_to_index.pkl',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d99a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"train.parquet\")\n",
    "\n",
    "\n",
    "train_df[\"price\"] = pd.to_numeric(train_df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "product_metadata = train_df.groupby(\"product_id\").agg({\n",
    "    \"brand\": \"first\",\n",
    "    \"cat_0\": \"first\",\n",
    "    \"price\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "product_metadata[\"price\"] = product_metadata[\"price\"].fillna(0)\n",
    "\n",
    "product_metadata.to_csv(\"product_metadata.csv\", index=False)\n",
    "\n",
    "purchase_counts = (\n",
    "    train_df[\"product_id\"]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "purchase_counts.columns = [\"product_id\", \"purchase_count\"]\n",
    "\n",
    "purchase_counts.to_csv(\"product_popularity.csv\", index=False)\n",
    "\n",
    "print(\"Files created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15482c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved: 164453\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"train.parquet\")\n",
    "\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "product_metadata = (\n",
    "    df.groupby(\"product_id\")\n",
    "    .agg({\n",
    "        \"brand\": \"first\",\n",
    "        \"cat_0\": \"first\",\n",
    "        \"price\": \"mean\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "product_metadata[\"price\"] = product_metadata[\"price\"].fillna(0)\n",
    "\n",
    "product_metadata.to_csv(\"product_metadata.csv\", index=False)\n",
    "\n",
    "print(\"Metadata saved:\", len(product_metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098738e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"train.parquet\")\n",
    "\n",
    "train_df[\"price\"] = pd.to_numeric(train_df[\"price\"], errors=\"coerce\")\n",
    "\n",
    "product_metadata = (\n",
    "    train_df\n",
    "    .groupby(\"product_id\")\n",
    "    .agg({\n",
    "        \"brand\": \"first\",\n",
    "        \"cat_0\": \"first\",\n",
    "        \"price\": \"mean\"\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "product_metadata[\"price\"] = product_metadata[\"price\"].fillna(0)\n",
    "\n",
    "product_metadata.to_csv(\"product_metadata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99692a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_popularity = (\n",
    "    train_df\n",
    "    .groupby(\"product_id\")\n",
    "    .size()\n",
    "    .reset_index(name=\"purchase_count\")\n",
    ")\n",
    "\n",
    "product_popularity.to_csv(\"product_popularity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4e36e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "index_to_product = pickle.load(open(\"index_to_product.pkl\", \"rb\"))\n",
    "\n",
    "product_metadata = pd.read_csv(\"product_metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4594f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(type(list(index_to_product.values())[0]))\n",
    "print(product_metadata[\"product_id\"].dtype)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
